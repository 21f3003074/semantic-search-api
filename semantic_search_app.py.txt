import time
import os
import numpy as np
from fastapi import FastAPI
from pydantic import BaseModel
from openai import OpenAI

app = FastAPI()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Dummy docs (replace later if needed)
documents = [
    {"id": i, "content": f"API documentation about authentication method {i}"}
    for i in range(113)
]

# -----------------
# Embedding
# -----------------
def get_embedding(text: str):
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return np.array(response.data[0].embedding)

# -----------------
# Build vector store
# -----------------
doc_embeddings = []
doc_texts = []
doc_ids = []

print("Creating embeddings...")

for doc in documents:
    emb = get_embedding(doc["content"])
    doc_embeddings.append(emb)
    doc_texts.append(doc["content"])
    doc_ids.append(doc["id"])

doc_embeddings = np.vstack(doc_embeddings)

# -----------------
# Cosine similarity
# -----------------
def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

# -----------------
# Vector search
# -----------------
def vector_search(query: str, k: int = 5):
    query_emb = get_embedding(query)

    scores = []
    for i, doc_emb in enumerate(doc_embeddings):
        sim = cosine_similarity(query_emb, doc_emb)
        scores.append((i, sim))

    scores.sort(key=lambda x: x[1], reverse=True)
    top = scores[:k]

    results = []
    for idx, score in top:
        results.append({
            "id": doc_ids[idx],
            "score": float(score),
            "content": doc_texts[idx],
            "metadata": {"source": "vector_search"}
        })

    return results

# -----------------
# Reranking
# -----------------
def rerank_results(query: str, candidates: list, top_k: int = 3):
    reranked = []

    for doc in candidates:
        prompt = f"""
Query: "{query}"
Document: "{doc['content']}"

Rate relevance from 0-10.
Only return the number.
"""

        response = client.responses.create(
            model="gpt-4.1-mini",
            input=prompt
        )

        score_text = response.output_text.strip()

        try:
            score = float(score_text) / 10.0
        except:
            score = 0.0

        doc["score"] = score
        reranked.append(doc)

    reranked.sort(key=lambda x: x["score"], reverse=True)
    return reranked[:top_k]

# -----------------
# Request model
# -----------------
class SearchRequest(BaseModel):
    query: str
    k: int = 5
    rerank: bool = True
    rerankK: int = 3

# -----------------
# API endpoint
# -----------------
@app.post("/search")
def semantic_search(req: SearchRequest):
    start_time = time.time()

    candidates = vector_search(req.query, req.k)

    if req.rerank and candidates:
        final_results = rerank_results(req.query, candidates, req.rerankK)
        reranked_flag = True
    else:
        final_results = candidates[:req.rerankK]
        reranked_flag = False

    latency = int((time.time() - start_time) * 1000)

    return {
        "results": final_results,
        "reranked": reranked_flag,
        "metrics": {
            "latency": latency,
            "totalDocs": len(documents)
        }
    }